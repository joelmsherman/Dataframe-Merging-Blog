{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Basics of Merging Dataframes in Pandas\n",
    "\n",
    "As I continue to learn Python's data science toolkit (which seems as vast and as ever-expanding as the universe, by the way), I've come across some useful information in how to manipulate pandas dataframes, and also some of the basics with generating plots in Matplotlib.  I wrote about that experience [here](https://medium.com/@joelmsherman/adventures-in-python-15fd17ca211e) and [here](https://medium.com/@joelmsherman/basic-data-viz-with-matplotlib-602c885f8093) because the best way to learn is to try to explain things to others, right?  \n",
    "\n",
    "In this installment of learning by teaching, I will tackle some of the basics of merging dataframes in Pandas. But before I get into it, you may be wondering what I mean by **merging dataframes** and maybe more importantly, why you should care about the topic.\n",
    "\n",
    "## What is \"Merging\" and Why Is It Important?\n",
    "\n",
    "When doing data analysis, more often than not one needs to work with more than one data table or data source.  Kaggle is nice for providing nice clean single csv files for your machine learning project, but this often isn't how we do our work in the real-world.  It's estimated and commonly cited that the bulk (80%) of a data scientist's time is spent data wrangling and cleaning.  Merging comes into place when we need to combine multiple datasets or disparate sources of data into one unified frame for analysis.  \n",
    "\n",
    "Quite literally, we can combine data vertically (stack two or more tables with similar columns to combine rows) or horizontally (stack two or more tables with similar rows to combine columns), and Pandas offers a variety of tools for doing this, including **append()**, **concat()**, **join()** and, you guessed it, **merge()**.  And when I use the term \"merge\", I refer to any and all of these methods unless I specifically state \"merge method\".\n",
    "\n",
    "## Why Not Do Your Merging In SQL?\n",
    "\n",
    "I know what you're thinking, and as a long-time SQL developer, let me just say duh!  This concept is so engrained in SQL's DNA that it's hard not to want to prepare or engineer your frame in SQL first, before bringing it into a development environment for further modeling and analysis.  But here's the problem:  not all data worthy of analysis is structured, nor lives in an RMDBMS! More (most?) often, the data we need for machine learning models or data visualizations is ad hoc, highly unstructured and dispersed in a variety of locations.  Once again, the power of Pandas and merging!\n",
    "\n",
    "Iâ€™ll stick with my own personal sleep and training data for this exercise (pun intended) and make the files available on my public github account [here](https://github.com/joelmsherman/explain_dataframe-merging/blob/master/sleep.csv) and [here](https://github.com/joelmsherman/explain_dataframe-merging/blob/master/training_recovery.csv) in case anyone wants to replicate my work here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Locate Data Sources\n",
    "url_sleep = 'https://raw.githubusercontent.com/joelmsherman/explain_dataframe-merging/master/sleep.csv'\n",
    "url_trainrecov = 'https://raw.githubusercontent.com/joelmsherman/explain_dataframe-merging/master/training_recovery.csv'\n",
    "\n",
    "# Identify Desired Columns\n",
    "cols_sleep = ['date',\n",
    "              'Total Sleep Time',\n",
    "              'Awake Time',\n",
    "              'REM Sleep Time',\n",
    "              'Light Sleep Time',\n",
    "              'Deep Sleep Time',\n",
    "              'Restless Sleep',\n",
    "              'Sleep Efficiency',\n",
    "              'Sleep Latency',\n",
    "              'Average Resting Heart Rate',\n",
    "              'Lowest Resting Heart Rate',\n",
    "              'Average HRV',\n",
    "              'Temperature Deviation',\n",
    "              'Respiratory Rate']\n",
    "\n",
    "cols_trainrecov = ['date',\n",
    "                   'HRV4T_Recovery_Points',\n",
    "                   'trainingRPE',\n",
    "                   'trainingTSS',\n",
    "                   'alcohol']\n",
    "\n",
    "# Read the data into Pandas Dataframes\n",
    "Sleep = pd.read_csv(url_sleep,skipinitialspace=True, usecols=cols_sleep)\n",
    "TrRec = pd.read_csv(url_trainrecov, skipinitialspace=True, usecols=cols_trainrecov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Dataframe 1: Sleep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up and set the index\n",
    "Sleep['date'] = pd.to_datetime(Sleep['date']).dt.date\n",
    "Sleep.set_index('date', inplace=True)\n",
    "\n",
    "# Column labels\n",
    "Sleep.columns = ['TotalSleep', 'Awake', 'REM', 'Light', 'Deep', 'Restless', 'Efficiency', 'Latency', 'AvgRHR', 'LowRHR', 'AvgHRV', 'TDiff', 'RespR']\n",
    "\n",
    "# Fill NaN with mean of each column for which the NaN exists\n",
    "Sleep = Sleep.fillna(Sleep.mean()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Dataframe 2: Training and Recovery Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up and set the index\n",
    "TrRec['date'] = pd.to_datetime(TrRec['date']).dt.date\n",
    "TrRec.set_index('date', inplace=True)\n",
    "\n",
    "# Column labels\n",
    "TrRec.columns = ['RecPts', 'RPE', 'TSS', 'Beers']\n",
    "\n",
    "# Convert Recovery pts to numeric and assign mean to NaN\n",
    "TrRec['RecPts'] = pd.to_numeric(TrRec['RecPts'], errors='coerce')\n",
    "TrRec['RecPts'] = TrRec['RecPts'].fillna((TrRec['RecPts'].mean()))\n",
    "\n",
    "# Convert RPE to numeric and assign zero to NaN for non-workout days\n",
    "TrRec['RPE'] = pd.to_numeric(TrRec['RPE'], errors='coerce')\n",
    "TrRec['RPE'] = TrRec['RPE'].fillna(0)\n",
    "\n",
    "# Convert TSS to numeric and imput NaN based on values of RPE\n",
    "TrRec['TSS'] = pd.to_numeric(TrRec['TSS'], errors='coerce')\n",
    "conditions = [TrRec['RPE']==0, TrRec['RPE'].between(0.1, 3), TrRec['RPE'].between(3.1, 5), TrRec['RPE'].between(5.1, 7), TrRec['RPE'] > 7]\n",
    "values = [0, 41, 53, 77, 85]\n",
    "TrRec['TSS'] = np.where(TrRec['TSS'].isnull(),\n",
    "                              np.select(conditions, values),\n",
    "                              TrRec['TSS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Dataframes into STR (Sleep, Training and Recovery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "STR = pd.merge(Sleep, TrRec, on='date')\n",
    "STR.to_csv('STR.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Medium Article from Here Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset Sleep df into two separate frames with 7 records each, and with only 'REM', 'Deep' and 'Light' cols\n",
    "# Subset TrRec df into a 14 day period (same days above)  and with only 'RecPts', 'RPE' and 'TSS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Pick up Article Here] After some subsetting and data cleaning, let's say I have two, one-week spans of sleep data that look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Sleep1, Sleep2 frames side by side?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And one, two-week span of training and recovery data that looks like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print TrRec df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we bring these dataframes together into one dataframe for analysis?  Let's start with the sleep data, which are weekly files of the same structure.  We obviously need to stack these frames vertically, and we have a couple options.  \n",
    "\n",
    "### Option 1: Append()\n",
    "\n",
    "The append method is like a SQL union, and allows dataframes to be merged vertically, on top of each other. We can do this to our sleep dataframes using append() like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo Append"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Concat()\n",
    "\n",
    "As an alternative to append, concat can merge dataframes either vertically or horizontally, using the axix=1 for the latter, and axis=0 for the former.  Here it is in action for our sleep dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo Concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  We've now got a single sleep dataframe with data for a two week period.  Now we just need to keep playing our game of tetris and merge our training and recovery data to this and we're done.  Here again, we've got a couple of options, this time for merging horizontally.\n",
    "\n",
    "### Option 1: Concat()\n",
    "\n",
    "### Option 2: Join()\n",
    "\n",
    "### Option 3: Merge() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
